{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "66759a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "71ae2183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn Styling\n",
    "sns.set()\n",
    "sns.set_context(\"poster\", font_scale = 1.25)\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ff7d02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment constants\n",
    "modes = ['once-per-minute', 'once-per-five-minutes', 'once-per-hour']\n",
    "platforms = {\n",
    "            #  \"pypy\": ['bfs', 'compress', 'dfs', 'mst', 'dynamic-html', 'pagerank'],\n",
    "             \"pypy\": ['bfs','dfs', 'mst', 'dynamic-html', 'pagerank', 'compress', 'upload', 'thumbnail', 'video'],\n",
    "             \"jvm\": ['matrix-multiplication', 'word-count', 'simple-hash', 'html-rendering']\n",
    "            }\n",
    "strategies = ['cold', 'fixed&request_to_checkpoint=1', 'request_centric&max_capacity=12' ]\n",
    "eviction_rates = [1, 4, 20]\n",
    "mutabilities = [1]\n",
    "df_columns = ['request_number', 'benchmark', 'mutability', 'strategy', 'client', 'server', 'overhead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1e051b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergence(platform: str, benchmark: str, eviction_rate: np.int64):\n",
    "    df = None\n",
    "    # Select the appropriate file for the given eviction rate.\n",
    "    if platform == \"pypy\":\n",
    "        python_cold_df = pd.read_csv(f'python-cold-{eviction_rate}.csv', names=df_columns)\n",
    "        python_fixed_df = pd.read_csv(f'python-fixed-1-{eviction_rate}.csv', names=df_columns)\n",
    "        python_req_df = pd.read_csv(f'python-request-centric-{eviction_rate}.csv', names=df_columns)\n",
    "        df = pd.concat([python_cold_df, python_fixed_df, python_req_df])\n",
    "    else:\n",
    "        java_cold_df = pd.read_csv(f'java-cold-{eviction_rate}.csv', names=df_columns)\n",
    "        java_fixed_df = pd.read_csv(f'java-fixed-1-{eviction_rate}.csv', names=df_columns)\n",
    "        java_req_df = pd.read_csv(f'java-request-centric-{eviction_rate}.csv', names=df_columns)\n",
    "        df = pd.concat([java_cold_df, java_fixed_df, java_req_df])\n",
    "\n",
    "    # if df == None:\n",
    "    #     print(\"Something went wrong.\")\n",
    "        \n",
    "    # Extract data only for the request centric strategy\n",
    "    df = df[df['strategy'] == 'request_centric&max_capacity=12']\n",
    "        \n",
    "    # Extract the data for the provided benchmark and mutability.\n",
    "    df = df[(df['benchmark'] == benchmark)]\n",
    "    \n",
    "    # Extract server-side latency from the data frame.\n",
    "    latencies = df['client'].to_numpy()\n",
    "    \n",
    "    # Calculate the target latency\n",
    "    target = np.median(df[df['request_number'] >= (0.8 * 500)]['client'].to_numpy())\n",
    "    \n",
    "    # Acceptable deviation from target: target Â± error\n",
    "    # Chosen Error Value: 2%\n",
    "    target_l = target * (0.98)\n",
    "    target_h = target * (1.02)\n",
    "    \n",
    "    # Slide a window over latencies of size N to find window closest to target\n",
    "    window_size = 20\n",
    "    \n",
    "    if platform == \"pypy\":\n",
    "        for index in range(0, len(latencies)):\n",
    "            if index < 100:\n",
    "                continue\n",
    "            window = latencies[index : window_size + index]\n",
    "            window_median = np.median(window)\n",
    "            if target_l <= window_median <= target_h:\n",
    "                return index\n",
    "    \n",
    "    else:\n",
    "        for index in range(0, len(latencies)):\n",
    "            if index < 200:\n",
    "                continue\n",
    "            window = latencies[index : window_size + index]\n",
    "            window_median = np.median(window)\n",
    "            if target_l <= window_median <= target_h:\n",
    "                return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef173c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {}\n",
    "for platform in platforms:\n",
    "    table[platform] = {}\n",
    "    for benchmark in platforms[platform]:\n",
    "        table[platform][benchmark] = {}\n",
    "        for mutability in mutabilities:\n",
    "            table[platform][benchmark][mutability] = {}\n",
    "            for eviction_rate in eviction_rates:\n",
    "                table[platform][benchmark][mutability][eviction_rate] = convergence(platform, benchmark, eviction_rate)\n",
    "                \n",
    "for platform in platforms:\n",
    "    for benchmark in platforms[platform]:\n",
    "        for mutability in mutabilities:\n",
    "            for eviction_rate in eviction_rates:\n",
    "                if eviction_rate == 4:\n",
    "                    print(f\"{benchmark}: {table[platform][benchmark][mutability][eviction_rate]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6119924a",
   "metadata": {},
   "source": [
    "# Performance Numbers (CDFs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "179e3cf2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "71dab39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_titles = {\n",
    "\"bfs\": 'BFS',\n",
    "\"dfs\": 'DFS',\n",
    "\"dynamic-html\": 'DynamicHTML',\n",
    "\"mst\": 'MST',\n",
    "\"pagerank\": 'PageRank',\n",
    "\"compress\": 'Compression',\n",
    "\"upload\": 'Uploader',\n",
    "\"thumbnail\": 'Thumbnailer',\n",
    "\"video\":'Video',\n",
    "\"matrix-multiplication\": 'MatrixMult',\n",
    "\"simple-hash\": 'Hash',\n",
    "\"html-rendering\": 'HTML Rendering',\n",
    "\"word-count\": 'WordCount',\n",
    "}\n",
    "platforms = [\"python\", \"java\"]\n",
    "eviction_rates = [1, 4, 20]\n",
    "strategies = ['cold', 'fixed-1', 'request-centric']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d22ea17",
   "metadata": {},
   "source": [
    "## Orchestration Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f01a5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for platform in platforms:            \n",
    "    for strategy in strategies:\n",
    "        df = pd.read_csv(f'{platform}-{strategy}-1.csv', names=df_columns)\n",
    "        df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a242c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby([\"benchmark\", \"strategy\"]).median()[\"client\"].reset_index()\n",
    "df_pivot = df_grouped.pivot(index='benchmark', columns='strategy', values='client')\n",
    "\n",
    "# Calculating improvement\n",
    "df_pivot['improvement'] = (df_pivot['fixed&request_to_checkpoint=1'] - df_pivot['request_centric&max_capacity=12']) / df_pivot['fixed&request_to_checkpoint=1'] * 100\n",
    "\n",
    "# Filter out rows where improvement is less than or equal to 0\n",
    "df_pivot_positive = df_pivot[df_pivot['improvement'] > 5]\n",
    "\n",
    "# Find the benchmark with the minimum positive improvement\n",
    "min_positive_improvement_benchmark = df_pivot_positive['improvement'].idxmin()\n",
    "\n",
    "print(f\"The benchmark with the minimum positive improvement is: {min_positive_improvement_benchmark}\")\n",
    "\n",
    "max_improvement_benchmark = df_pivot['improvement'].idxmax()\n",
    "\n",
    "print(f\"The benchmark with the maximum improvement is: {max_improvement_benchmark}\")\n",
    "\n",
    "# print improvement of each benchmark\n",
    "print(df_pivot['improvement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric Mean\n",
    "\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# List of specific benchmarks\n",
    "benchmarks_list = [\"bfs\", \"dfs\", \"dynamic-html\", \"mst\", \"pagerank\", \"compress\", \"thumbnail\", \"upload\", \"video\", \"matrix-multiplication\", \"simple-hash\", \"word-count\", \"html-rendering\"]  # Replace with actual benchmarks\n",
    "print(f\"Number of benchmarks: {len(benchmarks_list)}\")\n",
    "\n",
    "# Filter df for these benchmarks\n",
    "df_filtered = df[df[\"benchmark\"].isin(benchmarks_list)]\n",
    "\n",
    "# Calculate the median overhead for each benchmark and strategy\n",
    "df_grouped = df_filtered.groupby([\"benchmark\", \"strategy\"]).median()[\"client\"].reset_index()\n",
    "\n",
    "# Pivot the table to have each strategy as a separate column\n",
    "df_pivot = df_grouped.pivot(index='benchmark', columns='strategy', values='client')\n",
    "\n",
    "# Calculate the improvement\n",
    "df_pivot['improvement'] = (df_pivot['fixed&request_to_checkpoint=1'] - df_pivot['request_centric&max_capacity=12']) / df_pivot['fixed&request_to_checkpoint=1'] * 100\n",
    "\n",
    "# Define thresholds for different categories\n",
    "threshold_positive = 5.0  # 5% improvement threshold\n",
    "threshold_negative = -5.0  # -5% improvement threshold\n",
    "\n",
    "improved_benchmarks = df_pivot[df_pivot['improvement'] > threshold_positive].index\n",
    "on_par_benchmarks = df_pivot[(df_pivot['improvement'] >= threshold_negative) & (df_pivot['improvement'] <= threshold_positive)].index\n",
    "worsened_benchmarks = df_pivot[df_pivot['improvement'] < threshold_negative].index\n",
    "\n",
    "print(f\"Benchmarks (and corresponding rates) that improved: {improved_benchmarks.tolist()}\")\n",
    "print(f\"Number of benchmarks that improved: {len(improved_benchmarks)}\")\n",
    "print(f\"Benchmarks (and corresponding rates) that are on par: {on_par_benchmarks.tolist()}\")\n",
    "print(f\"Number of benchmarks that are on par: {len(on_par_benchmarks)}\")\n",
    "print(f\"Benchmarks (and corresponding rates) that worsened: {worsened_benchmarks.tolist()}\")\n",
    "print(f\"Number of benchmarks that worsened: {len(worsened_benchmarks)}\")\n",
    "\n",
    "# Filter out rows where improvement is less than or equal to threshold_negative\n",
    "df_pivot_positive = df_pivot[df_pivot['improvement'] > threshold_positive]\n",
    "\n",
    "# Calculate geometric mean of the median improvements\n",
    "geo_mean_improvement = gmean(df_pivot_positive['improvement'])\n",
    "\n",
    "print(f\"The geometric mean of the median percentage improvements for the benchmarks with positive improvements is: {geo_mean_improvement:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eef4a2f3",
   "metadata": {},
   "source": [
    "## Request Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "abfaac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for platform in platforms: \n",
    "  for strategy in strategies:\n",
    "    for rate in eviction_rates:           \n",
    "        df = pd.read_csv(f'{platform}-{strategy}-{rate}.csv', names=df_columns)\n",
    "        df[\"rate\" ] = rate\n",
    "        df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd006de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "\n",
    "# Calculate the median client times for each benchmark, strategy, and rate\n",
    "df_grouped = df.groupby([\"benchmark\", \"strategy\", \"rate\"]).median()[\"client\"].reset_index()\n",
    "\n",
    "# Pivot the table to have each strategy as a separate column, while maintaining benchmark and rate in the index\n",
    "df_pivot = df_grouped.pivot(index=['benchmark', 'rate'], columns='strategy', values='client')\n",
    "\n",
    "# Calculate the improvement\n",
    "df_pivot['improvement'] = (df_pivot['fixed&request_to_checkpoint=1'] - df_pivot['request_centric&max_capacity=12']) / df_pivot['fixed&request_to_checkpoint=1'] * 100\n",
    "\n",
    "# Filter out rows where improvement is less than or equal to 5%\n",
    "df_pivot_positive = df_pivot[df_pivot['improvement'] > 5].reset_index()\n",
    "\n",
    "# Calculate geometric mean of the median improvements for each rate\n",
    "geo_mean_improvement_per_rate = df_pivot_positive.groupby(\"rate\")['improvement'].apply(gmean)\n",
    "\n",
    "print(f\"The geometric mean of the median improvements per rate is:\\n{geo_mean_improvement_per_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df6e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "\n",
    "# Calculate the median client times for each benchmark, strategy, and rate\n",
    "df_grouped = df.groupby([\"benchmark\", \"strategy\", \"rate\"]).median()[\"client\"].reset_index()\n",
    "\n",
    "# Pivot the table to have each strategy as a separate column, while maintaining benchmark and rate in the index\n",
    "df_pivot = df_grouped.pivot(index=['benchmark', 'rate'], columns='strategy', values='client')\n",
    "\n",
    "# Calculate the percentage improvement\n",
    "df_pivot['improvement'] = (df_pivot['fixed&request_to_checkpoint=1'] - df_pivot['request_centric&max_capacity=12']) / df_pivot['fixed&request_to_checkpoint=1'] * 100\n",
    "\n",
    "# Define thresholds for different categories\n",
    "threshold_positive = 5.0  # 5% improvement threshold\n",
    "threshold_negative = -5.0  # -5% improvement threshold\n",
    "\n",
    "# Find benchmarks that improve, worsen, and are on par\n",
    "improved_benchmarks = df_pivot[df_pivot['improvement'] > threshold_positive].index\n",
    "on_par_benchmarks = df_pivot[(df_pivot['improvement'] >= threshold_negative) & (df_pivot['improvement'] <= threshold_positive)].index\n",
    "worsened_benchmarks = df_pivot[df_pivot['improvement'] < threshold_negative].index\n",
    "\n",
    "print(f\"Benchmarks (and corresponding rates) that improved: {improved_benchmarks.tolist()}\")\n",
    "print(f\"Number of benchmarks that improved: {len(improved_benchmarks)}\")\n",
    "print(f\"Benchmarks (and corresponding rates) that are on par: {on_par_benchmarks.tolist()}\")\n",
    "print(f\"Number of benchmarks that are on par: {len(on_par_benchmarks)}\")\n",
    "print(f\"Benchmarks (and corresponding rates) that worsened: {worsened_benchmarks.tolist()}\")\n",
    "print(f\"Number of benchmarks that worsened: {len(worsened_benchmarks)}\")\n",
    "\n",
    "# Filter out rows where improvement is less than or equal to threshold_negative\n",
    "df_pivot_positive = df_pivot[df_pivot['improvement'] > threshold_positive]\n",
    "\n",
    "# Calculate geometric mean of the median improvements\n",
    "geo_mean_improvement = gmean(df_pivot_positive['improvement'])\n",
    "\n",
    "print(f\"The geometric mean of the median percentage improvements for the benchmarks with positive improvements is: {geo_mean_improvement:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
